# OpenTelemetry Data Lake Bridge - Test Data Generator Configuration
# 
# This configuration file demonstrates comprehensive test data generation
# for agentic IDE telemetry patterns with realistic workflow modeling.

name = "agentic-ide-test-data-generator"
version = "0.1.0"
seed = 42

[output]
directory = "test-data"
format = "Json"
compression = { enabled = true, algorithm = "Gzip", level = 6 }
batch_size = 1000
max_file_size = 104857600  # 100MB


[deployment]
deployment_frequency = 0.1
rollback_rate = 0.02
environment_count = 3
[deployment.deployment_time]
min_seconds = 300
max_seconds = 1800
mean_seconds = 900
std_dev_seconds = 450
distribution_type = "Normal"

[code_review]
review_frequency = 0.2
reviewer_count = 2
approval_rate = 0.9

[code_review.review_time]
min_seconds = 300
max_seconds = 1800
mean_seconds = 900
std_dev_seconds = 450
distribution_type = "Normal"

[workflow.research]
session_duration = { min_seconds = 300, max_seconds = 3600, mean_seconds = 1800, std_dev_seconds = 600, distribution_type = "Normal" }
query_patterns = [
    { name = "semantic_search", frequency = 0.4, complexity = "Moderate", attributes = { "search_type" = "semantic", "domain" = "code" } },
    { name = "documentation_lookup", frequency = 0.3, complexity = "Simple", attributes = { "search_type" = "keyword", "domain" = "docs" } },
    { name = "code_analysis", frequency = 0.2, complexity = "Complex", attributes = { "search_type" = "structured", "domain" = "analysis" } },
    { name = "research_synthesis", frequency = 0.1, complexity = "VeryComplex", attributes = { "search_type" = "natural_language", "domain" = "synthesis" } }
]
knowledge_graph_interactions = { node_count = 1000, edge_count = 5000, query_frequency = 0.1, traversal_depth = 3 }
citation_tracking = { citation_count = 10, source_diversity = 0.8, tracking_frequency = 0.05 }

[workflow.coordination]
multi_repo_coordination = { repository_count = 5, dependency_depth = 3, coordination_frequency = 0.2, merge_conflict_rate = 0.1 }

[workflow.coordination.agent_coordination]
agent_count = 3
handoff_frequency = 0.15
escalation_rate = 0.05
coordination_patterns = [
    { name = "sequential_handoff", frequency = 0.4, complexity = "Simple", attributes = { pattern_type = "sequential" } },
    { name = "parallel_collaboration", frequency = 0.3, complexity = "Moderate", attributes = { pattern_type = "parallel" } },
    { name = "hierarchical_decision", frequency = 0.2, complexity = "Complex", attributes = { pattern_type = "hierarchical" } },
    { name = "peer_review", frequency = 0.1, complexity = "Moderate", attributes = { pattern_type = "peer" } }
]

[workflow.implementation.conflict_resolution]
conflict_rate = 0.1
resolution_time = { min_seconds = 60, max_seconds = 1800, mean_seconds = 600, std_dev_seconds = 300, distribution_type = "Normal" }
resolution_strategies = [
    { name = "automatic_merge", frequency = 0.6, success_rate = 0.9 },
    { name = "manual_resolution", frequency = 0.3, success_rate = 0.95 },
    { name = "rollback_and_retry", frequency = 0.1, success_rate = 0.8 }
]
decision_making = { decision_frequency = 0.1, participant_count = 3, decision_time = { min_seconds = 300, max_seconds = 3600, mean_seconds = 1800, std_dev_seconds = 900, distribution_type = "Normal" }, consensus_rate = 0.8 }

[workflow.implementation.code_generation]
generation_frequency = 0.3
code_complexity = "Moderate"
generation_time = { min_seconds = 60, max_seconds = 1800, mean_seconds = 600, std_dev_seconds = 300, distribution_type = "Normal" }
language_distribution = { rust = 0.4, python = 0.3, typescript = 0.2, go = 0.1 }

[workflow.implementation.testing]
test_coverage = 0.8
test_types = ["Unit", "Integration"]
test_execution_time = { min_seconds = 30, max_seconds = 600, mean_seconds = 180, std_dev_seconds = 120, distribution_type = "Normal" }
failure_rate = 0.05 

[workflow.agent_interactions]
agent_types = ["ResearchAgent", "CodeAgent", "TestAgent", "ReviewAgent", "CoordinationAgent"]
interaction_patterns = [
    { name = "collaboration", frequency = 0.3, duration = { min_seconds = 60, max_seconds = 300, mean_seconds = 180, std_dev_seconds = 60, distribution_type = "Normal" }, complexity = "Moderate" },
    { name = "handoff", frequency = 0.15, duration = { min_seconds = 10, max_seconds = 60, mean_seconds = 30, std_dev_seconds = 15, distribution_type = "Normal" }, complexity = "Simple" },
    { name = "escalation", frequency = 0.05, duration = { min_seconds = 300, max_seconds = 1800, mean_seconds = 900, std_dev_seconds = 450, distribution_type = "Normal" }, complexity = "Complex" },
    { name = "decision_support", frequency = 0.1, duration = { min_seconds = 120, max_seconds = 600, mean_seconds = 300, std_dev_seconds = 150, distribution_type = "Normal" }, complexity = "Moderate" }
]
escalation_patterns = [
    { name = "technical_difficulty", frequency = 0.4, escalation_reasons = ["complex_algorithm", "performance_issue", "integration_problem"], resolution_time = { min_seconds = 600, max_seconds = 3600, mean_seconds = 1800, std_dev_seconds = 900, distribution_type = "Normal" } },
    { name = "resource_constraint", frequency = 0.3, escalation_reasons = ["memory_limit", "timeout", "concurrent_limit"], resolution_time = { min_seconds = 300, max_seconds = 1800, mean_seconds = 900, std_dev_seconds = 450, distribution_type = "Normal" } },
    { name = "coordination_issue", frequency = 0.2, escalation_reasons = ["conflict", "dependency", "communication"], resolution_time = { min_seconds = 900, max_seconds = 5400, mean_seconds = 2700, std_dev_seconds = 1350, distribution_type = "Normal" } },
    { name = "security_concern", frequency = 0.1, escalation_reasons = ["vulnerability", "compliance", "access_control"], resolution_time = { min_seconds = 1800, max_seconds = 7200, mean_seconds = 3600, std_dev_seconds = 1800, distribution_type = "Normal" } }
]
collaboration_patterns = [
    { name = "pair_programming", frequency = 0.4, participant_count = 2, collaboration_time = { min_seconds = 1800, max_seconds = 7200, mean_seconds = 3600, std_dev_seconds = 1800, distribution_type = "Normal" } },
    { name = "team_review", frequency = 0.3, participant_count = 3, collaboration_time = { min_seconds = 900, max_seconds = 3600, mean_seconds = 1800, std_dev_seconds = 900, distribution_type = "Normal" } },
    { name = "cross_team_coordination", frequency = 0.2, participant_count = 5, collaboration_time = { min_seconds = 3600, max_seconds = 14400, mean_seconds = 7200, std_dev_seconds = 3600, distribution_type = "Normal" } },
    { name = "stakeholder_meeting", frequency = 0.1, participant_count = 8, collaboration_time = { min_seconds = 1800, max_seconds = 5400, mean_seconds = 2700, std_dev_seconds = 1350, distribution_type = "Normal" } }
]

[workflow.repository_operations]
operation_types = ["Pull", "Push", "Commit", "Merge", "Branch", "Tag"]
operation_frequency = 0.4
operation_time = { min_seconds = 10, max_seconds = 300, mean_seconds = 60, std_dev_seconds = 30, distribution_type = "Normal" }
error_rate = 0.02

[workflow.user_behavior]
user_personas = [
    { name = "senior_developer", frequency = 0.3, characteristics = { "experience" = "senior", "productivity" = "high", "complexity_preference" = "high" }, behavior_patterns = ["research_driven", "code_review", "mentoring"] },
    { name = "mid_level_developer", frequency = 0.4, characteristics = { "experience" = "mid", "productivity" = "medium", "complexity_preference" = "medium" }, behavior_patterns = ["implementation_focused", "testing", "collaboration"] },
    { name = "junior_developer", frequency = 0.2, characteristics = { "experience" = "junior", "productivity" = "learning", "complexity_preference" = "low" }, behavior_patterns = ["learning", "pair_programming", "code_review"] },
    { name = "tech_lead", frequency = 0.1, characteristics = { "experience" = "lead", "productivity" = "high", "complexity_preference" = "very_high" }, behavior_patterns = ["architecture", "coordination", "decision_making"] }
]
activity_patterns = [
    { name = "morning_work", frequency = 0.3, duration = { min_seconds = 1800, max_seconds = 7200, mean_seconds = 3600, std_dev_seconds = 1800, distribution_type = "Normal" }, time_of_day = { start_hour = 9, end_hour = 12, peak_hours = [10, 11], timezone = "America/New_York" } },
    { name = "afternoon_work", frequency = 0.4, duration = { min_seconds = 1800, max_seconds = 7200, mean_seconds = 3600, std_dev_seconds = 1800, distribution_type = "Normal" }, time_of_day = { start_hour = 13, end_hour = 17, peak_hours = [14, 15], timezone = "America/New_York" } },
    { name = "evening_work", frequency = 0.2, duration = { min_seconds = 900, max_seconds = 3600, mean_seconds = 1800, std_dev_seconds = 900, distribution_type = "Normal" }, time_of_day = { start_hour = 18, end_hour = 22, peak_hours = [19, 20], timezone = "America/New_York" } },
    { name = "late_night_work", frequency = 0.1, duration = { min_seconds = 900, max_seconds = 1800, mean_seconds = 1200, std_dev_seconds = 600, distribution_type = "Normal" }, time_of_day = { start_hour = 22, end_hour = 2, peak_hours = [23, 0], timezone = "America/New_York" } }
]
session_patterns = [
    { name = "focused_coding", frequency = 0.4, session_duration = { min_seconds = 1800, max_seconds = 7200, mean_seconds = 3600, std_dev_seconds = 1800, distribution_type = "Normal" }, session_activities = ["coding", "testing", "debugging"] },
    { name = "research_session", frequency = 0.2, session_duration = { min_seconds = 900, max_seconds = 3600, mean_seconds = 1800, std_dev_seconds = 900, distribution_type = "Normal" }, session_activities = ["research", "documentation", "learning"] },
    { name = "collaboration_session", frequency = 0.3, session_duration = { min_seconds = 1800, max_seconds = 5400, mean_seconds = 2700, std_dev_seconds = 1350, distribution_type = "Normal" }, session_activities = ["pair_programming", "code_review", "planning"] },
    { name = "maintenance_session", frequency = 0.1, session_duration = { min_seconds = 900, max_seconds = 2700, mean_seconds = 1800, std_dev_seconds = 900, distribution_type = "Normal" }, session_activities = ["refactoring", "bug_fixes", "updates"] }
]
interaction_patterns = [
    { name = "typing", frequency = 0.4, interaction_type = "Type", interaction_time = { min_seconds = 1, max_seconds = 30, mean_seconds = 10, std_dev_seconds = 5, distribution_type = "Normal" } },
    { name = "navigation", frequency = 0.3, interaction_type = "Navigate", interaction_time = { min_seconds = 1, max_seconds = 10, mean_seconds = 3, std_dev_seconds = 2, distribution_type = "Normal" } },
    { name = "search", frequency = 0.2, interaction_type = "Search", interaction_time = { min_seconds = 5, max_seconds = 60, mean_seconds = 20, std_dev_seconds = 10, distribution_type = "Normal" } },
    { name = "command", frequency = 0.1, interaction_type = "Command", interaction_time = { min_seconds = 1, max_seconds = 15, mean_seconds = 5, std_dev_seconds = 3, distribution_type = "Normal" } }
]

[scale.volume]
total_events = 1_000_000
events_per_second = 1000
burst_multiplier = 2.0
data_retention_days = 30

[scale.temporal]
start_time = "2024-01-01T00:00:00Z"
end_time = "2024-01-08T00:00:00Z"
business_hours = { enabled = true, start_hour = 9, end_hour = 17, timezone = "America/New_York", activity_multiplier = 2.0 }
seasonal_patterns = [
    { name = "q1_planning", start_month = 1, end_month = 3, activity_multiplier = 1.2 },
    { name = "q2_development", start_month = 4, end_month = 6, activity_multiplier = 1.5 },
    { name = "q3_release", start_month = 7, end_month = 9, activity_multiplier = 1.8 },
    { name = "q4_maintenance", start_month = 10, end_month = 12, activity_multiplier = 0.8 }
]
event_clustering = { enabled = true, cluster_size = 10, cluster_frequency = 0.1, cluster_duration = { min_seconds = 60, max_seconds = 600, mean_seconds = 300, std_dev_seconds = 150, distribution_type = "Normal" } }

[scale.geographic]
regions = [
    { name = "us-east-1", frequency = 0.4, timezone = "America/New_York", compliance_requirements = ["GDPR", "CCPA"] },
    { name = "us-west-2", frequency = 0.3, timezone = "America/Los_Angeles", compliance_requirements = ["CCPA"] },
    { name = "eu-west-1", frequency = 0.2, timezone = "Europe/London", compliance_requirements = ["GDPR"] },
    { name = "ap-southeast-1", frequency = 0.1, timezone = "Asia/Singapore", compliance_requirements = ["PDPA"] }
]
latency_distribution = { min_ms = 10, max_ms = 200, mean_ms = 50, std_dev_ms = 30 }
bandwidth_distribution = { min_mbps = 10.0, max_mbps = 1000.0, mean_mbps = 100.0, std_dev_mbps = 50.0 }

[scale.multi_tenant]
tenant_count = 10
tenant_size_distribution = { small_tenants = 0.4, medium_tenants = 0.3, large_tenants = 0.2, enterprise_tenants = 0.1 }
isolation_level = "Strict"
cross_tenant_analytics = false

[scale.concurrency]
concurrent_users = 100
parallel_workflows = 10
batch_processing_size = 1000
streaming_velocity = 10000

[quality.schema_compliance]
opentelemetry_compliance = true
lakehouse_schema_mapping = true
custom_attributes = true
schema_migration = false

[quality.data_consistency]
cross_reference_validation = true
temporal_consistency = true
aggregation_consistency = true
cross_service_consistency = true

[quality.privacy_compliance]
pii_scrubbing = true
gdpr_compliance = true
ccpa_compliance = true
data_classification = true
audit_trail = true

[quality.realism]
workflow_realism = 0.9
timing_realism = 0.8
data_distribution_realism = 0.85
error_pattern_realism = 0.7

[[scenarios]]
name = "research-driven-development"
description = "Complete research-driven development workflow with realistic agentic patterns"
scenario_type = "Development"
enabled = true
parameters = { research_duration = "2h", coordination_complexity = "high", implementation_scope = "medium", agent_count = 3 }

[[scenarios]]
name = "multi-repo-coordination"
description = "Complex multi-repository coordination workflow with dependency management"
scenario_type = "Development"
enabled = true
parameters = { repo_count = 5, dependency_depth = 3, conflict_rate = 0.15, coordination_frequency = 0.2 }

[[scenarios]]
name = "agent-failures"
description = "Realistic agent failure and recovery patterns with escalation workflows"
scenario_type = "Failure"
enabled = true
parameters = { failure_rate = 0.05, recovery_time = "5m", escalation_rate = 0.3, handoff_frequency = 0.15 }

[[scenarios]]
name = "network-partitions"
description = "Desktop-cloud connectivity issues with offline operation and synchronization"
scenario_type = "Failure"
enabled = true
parameters = { partition_duration = "10m", sync_delay = "2m", data_loss_rate = 0.01, recovery_strategy = "eventual_consistency" }

[[scenarios]]
name = "high-volume-load"
description = "100K+ events per second with realistic burst patterns and backpressure testing"
scenario_type = "Scale"
enabled = true
parameters = { events_per_second = 100000, burst_multiplier = 3.0, duration = "1h", backpressure_threshold = 0.8 }

[[scenarios]]
name = "multi-tenant-scale"
description = "Large-scale multi-tenant scenario with proper isolation and compliance"
scenario_type = "Scale"
enabled = true
parameters = { tenant_count = 100, tenant_size = "large", isolation_level = "strict", compliance_requirements = ["GDPR", "CCPA"] }

[[scenarios]]
name = "schema-evolution"
description = "Testing schema migration and backward compatibility scenarios"
scenario_type = "Evolution"
enabled = true
parameters = { migration_strategy = "rolling", backward_compatibility = true, forward_compatibility = true, version_coexistence = true }

[[scenarios]]
name = "compliance-testing"
description = "GDPR and CCPA compliance scenarios with privacy-preserving data patterns"
scenario_type = "Compliance"
enabled = true
parameters = { gdpr_compliance = true, ccpa_compliance = true, data_retention = "90d", right_to_forget = true }

[additional_data]
metrics_data = { metric_types = ["Counter", "Gauge", "Histogram", "Summary"], cardinality = 1000, sampling_rate = 0.1 }
traces_data = { trace_depth = 10, span_count = 100, error_rate = 0.05, baggage_items = 5 }
logs_data = { log_levels = ["DEBUG", "INFO", "WARN", "ERROR"], structured_logs = true, log_volume = 10000 }
events_data = { event_types = ["workflow_start", "workflow_complete", "agent_interaction", "error"], event_volume = 5000, event_complexity = "Moderate" }

[validation]
schema_validation = true
data_validation = true
consistency_validation = true
quality_validation = true
performance_validation = false

[export]
formats = ["Json", "Parquet", "Delta"]
destinations = ["File(test-data)"]
compression = true
encryption = false
